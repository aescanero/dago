services:
  redis:
    image: redis:7-alpine
    container_name: dago-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3
    networks:
      - dago-network

  dago:
    build:
      context: ../..
      dockerfile: dago/deployments/docker/Dockerfile.monorepo
    image: aescanero/dago:0.1.1
    container_name: dago
    ports:
      - "8080:8080"
      - "9090:9090"
      - "2112:2112"  # Prometheus metrics
    environment:
      - REDIS_ADDR=redis:6379
      # LLM Configuration - Using Ollama on host by default (no API key needed)
      # Ollama must be running on the host: ollama serve
      - LLM_PROVIDER=${LLM_PROVIDER:-ollama}
      - LLM_BASE_URL=${LLM_BASE_URL:-http://host.docker.internal:11434}
      - LLM_MODEL=${LLM_MODEL:-llama3.1}
      - LLM_API_KEY=${LLM_API_KEY}  # Not required for Ollama
      - WORKER_POOL_SIZE=${WORKER_POOL_SIZE:-5}
      - LOG_LEVEL=${LOG_LEVEL:-info}
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "-O", "/dev/null", "http://localhost:8080/health"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 10s
    networks:
      - dago-network

  dashboard:
    image: aescanero/dago-dashboard:develop
    container_name: dago-dashboard
    ports:
      - "3000:80"
    environment:
      # Nginx will proxy these to the backend
      - API_BASE_URL=http://dago:8080
      - WS_URL=http://dago:8080
    depends_on:
      dago:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "-O", "/dev/null", "http://localhost/health"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 5s
    networks:
      - dago-network

  executor-worker:
    build:
      context: ../..
      dockerfile: dago-node-executor/deployments/docker/Dockerfile.monorepo
    image: aescanero/dago-node-executor:0.1.0
    container_name: dago-executor-worker
    environment:
      - REDIS_ADDR=redis:6379
      # LLM Configuration - Using Ollama on host by default (no API key needed)
      # Ollama must be running on the host: ollama serve
      # Supports: anthropic, openai, gemini, ollama
      - LLM_PROVIDER=${LLM_PROVIDER:-ollama}
      - LLM_BASE_URL=${LLM_BASE_URL:-http://host.docker.internal:11434}
      - LLM_MODEL=${LLM_MODEL:-llama3.1}
      - LLM_API_KEY=${LLM_API_KEY}  # Not required for Ollama
      - WORKER_ID=${EXECUTOR_WORKER_ID:-executor-1}
      - LOG_LEVEL=${LOG_LEVEL:-info}
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      redis:
        condition: service_healthy
      dago:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - dago-network

  router-worker:
    build:
      context: ../..
      dockerfile: dago-node-router/deployments/docker/Dockerfile.monorepo
    image: aescanero/dago-node-router:0.1.0
    container_name: dago-router-worker
    environment:
      - REDIS_ADDR=redis:6379
      # LLM Configuration - Using Ollama on host by default (no API key needed)
      # Ollama must be running on the host: ollama serve
      # Supports: anthropic, openai, gemini, ollama
      - LLM_PROVIDER=${LLM_PROVIDER:-ollama}
      - LLM_BASE_URL=${LLM_BASE_URL:-http://host.docker.internal:11434}
      - LLM_MODEL=${LLM_MODEL:-llama3.1}
      - LLM_API_KEY=${LLM_API_KEY}  # Not required for Ollama
      - WORKER_ID=${ROUTER_WORKER_ID:-router-1}
      - LOG_LEVEL=${LOG_LEVEL:-info}
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      redis:
        condition: service_healthy
      dago:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - dago-network

volumes:
  redis-data:
    driver: local

networks:
  dago-network:
    driver: bridge
